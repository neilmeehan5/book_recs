{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a Jupyter notebook to investigate the data before creating import script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as json\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.types import *\n",
    "from mysecrets import user, password\n",
    "\n",
    "engine = create_engine(f'postgresql://{user}:{password}@localhost:5432/book_recs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set datatypes\n",
    "dtypes = {\n",
    "    'book_id': pd.Int32Dtype(),\n",
    "    'work_id': pd.Int32Dtype(),\n",
    "    'title': pd.StringDtype(),\n",
    "    'title_without_series': pd.StringDtype(),\n",
    "    'isbn': pd.Int64Dtype(),\n",
    "    'isbn13': pd.Int64Dtype(),\n",
    "    'text_reviews_count': pd.Int32Dtype(),\n",
    "    'ratings_count': pd.Int32Dtype(),\n",
    "    'average_rating': pd.Float32Dtype(),\n",
    "    'series': pd.StringDtype(),\n",
    "    'country_code': pd.StringDtype(),\n",
    "    'language_code': pd.StringDtype(),\n",
    "    'asin': pd.StringDtype(),\n",
    "    'kindle_asin': pd.StringDtype(),\n",
    "    'is_ebook': pd.StringDtype(),\n",
    "    'description': pd.StringDtype(),\n",
    "    'link': pd.StringDtype(),\n",
    "    'url': pd.StringDtype(),\n",
    "    'image_url': pd.StringDtype(),\n",
    "    'num_pages': pd.Int32Dtype(),\n",
    "    'publication_day': pd.Int8Dtype(),\n",
    "    'publication_month': pd.Int8Dtype(),\n",
    "    'publication_year': pd.Int16Dtype(),\n",
    "    'format': pd.StringDtype(),\n",
    "    'publisher': pd.StringDtype(),\n",
    "    'edition_information': pd.StringDtype(),\n",
    "    'similar_books': pd.StringDtype(),\n",
    "    'authors': pd.StringDtype(),\n",
    "    'popular_shelves': pd.StringDtype()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking done.\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/'\n",
    "# FILE_PATH = '../data/'\n",
    "files = [\n",
    "    'goodreads_books', \n",
    "    'goodreads_book_authors', \n",
    "    # 'goodreads_book_genres_initial',\n",
    "    # 'goodreads_book_works'\n",
    "        ]\n",
    "\n",
    "chunked = pd.read_json(f'{FILE_PATH}{files[0]}.json.gz', \n",
    "                       lines=True, \n",
    "                       dtype=dtypes,\n",
    "                       chunksize=1000,\n",
    "                       compression='gzip')\n",
    "\n",
    "print('Chunking done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the schema for the tables\n",
    "BOOKS_SCHEMA = {\n",
    "    'book_id': Integer,\n",
    "    'work_id': Integer,\n",
    "    'title': Text,\n",
    "    'title_without_series': Text,\n",
    "    'isbn': BigInteger,\n",
    "    'isbn13': BigInteger,\n",
    "    'text_reviews_count': Integer,\n",
    "    'ratings_count': Integer,\n",
    "    'average_rating': Float,\n",
    "    'series': Text,\n",
    "    'country_code': Text,\n",
    "    'language_code': Text,\n",
    "    'asin': Text,\n",
    "    'kindle_asin': Text,\n",
    "    'is_ebook': Text,\n",
    "    'description': Text,\n",
    "    'link': Text,\n",
    "    'url': Text,\n",
    "    'image_url': Text,\n",
    "    'num_pages': Integer,\n",
    "    'publication_day': Integer,\n",
    "    'publication_month': Integer,\n",
    "    'publication_year': Integer,\n",
    "    'format': Text,\n",
    "    'publisher': Text,\n",
    "    'edition_information': Text,\n",
    "    'similar_books': Text\n",
    "}\n",
    "\n",
    "AUTHORS_SCHEMA = {\n",
    "    'author_id': Integer,\n",
    "    'work_id': Integer,\n",
    "    'role': Text\n",
    "}\n",
    "\n",
    "TAGS_SCHEMA = {\n",
    "    'work_id': Integer,\n",
    "    'name': Text,\n",
    "    'count':  Integer\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the columns which need to be converted\n",
    "to_conv = ['book_id',\n",
    "           'work_id',\n",
    "           'text_reviews_count',\n",
    "           'ratings_count',\n",
    "           'isbn',\n",
    "           'isbn13',\n",
    "           'num_pages',\n",
    "           'publication_day',\n",
    "           'publication_month',\n",
    "           'publication_year',\n",
    "           'average_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "counter = 1\n",
    "seen_works = set()\n",
    "\n",
    "for piece in chunked:\n",
    "    # filter to english books\n",
    "    piece = piece.loc[(piece['language_code'].str.contains('en')) | (piece['language_code'] == '')]\n",
    "\n",
    "    # deal with nested dictionaries\n",
    "    piece['popular_shelves'] = piece['popular_shelves'].apply(ast.literal_eval)\n",
    "    piece['authors'] = piece['authors'].apply(ast.literal_eval)\n",
    "\n",
    "    # get tags df\n",
    "    df_exploded = piece.explode('popular_shelves').reset_index(drop=True)\n",
    "    df_normalized = pd.json_normalize(df_exploded['popular_shelves']).reset_index(drop=True)\n",
    "    tags = df_exploded[['work_id']].join(df_normalized)\n",
    "\n",
    "    # only add unseen works\n",
    "    tags = tags[~tags['work_id'].isin(seen_works)]\n",
    "    new_seen = set(tags['work_id'])\n",
    "    seen_works = seen_works.union(new_seen)\n",
    "\n",
    "    tags[['work_id', 'count']] = tags[['work_id', 'count']].apply(pd.to_numeric, errors='coerce')\n",
    "    tags.to_sql('tags',\n",
    "                engine,\n",
    "                if_exists='append',\n",
    "                index=False,\n",
    "                dtype=TAGS_SCHEMA)\n",
    "\n",
    "    # get authors df\n",
    "    df_exploded = piece.explode('authors').reset_index(drop=True)\n",
    "    df_normalized = pd.json_normalize(df_exploded['authors']).reset_index(drop=True)\n",
    "    authors = df_exploded[['work_id']].join(df_normalized)\n",
    "    authors[['work_id', 'author_id']] = authors[['work_id', 'author_id']].apply(pd.to_numeric, errors='coerce')\n",
    "    authors.to_sql('authors',\n",
    "                   engine,\n",
    "                   if_exists='append',\n",
    "                   index=False,\n",
    "                   dtype=AUTHORS_SCHEMA)\n",
    "\n",
    "    # drop exploded columns\n",
    "    goodreads_books = piece.drop(['popular_shelves', 'authors'], axis=1)\n",
    "    goodreads_books[to_conv] = goodreads_books[to_conv].apply(pd.to_numeric, errors='coerce')\n",
    "    goodreads_books.to_sql('goodreads_books',\n",
    "                           engine,\n",
    "                           if_exists='append',\n",
    "                           index=False,\n",
    "                           dtype =BOOKS_SCHEMA)\n",
    "        \n",
    "    print(F'FINISHED CHUNK {counter}')\n",
    "    counter += 1\n",
    "\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
